%%%%% <arXiv>
%\documentclass[final,5p,times,twocolumn]{elsarticle}
%%%%% </arXiv>

%%%%% <gmd>
\documentclass[gmd]{copernicus}%_discussions}
%%%%% </gmd>

% input encoding assuring proper handling of Polish characters (surnames!)
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{type1cm}
\usepackage{relsize}

\input{formulae_preamble}

% for Arakawa-C figure
\usepackage{tikz}
\usetikzlibrary{calc}

% for conpact itemize etc
\usepackage{enumitem}
\setitemize{noitemsep,itemsep=1pt,topsep=1pt,parsep=0pt,partopsep=0pt}

% for source code listings
\usepackage{fancyvrb}
\fvset{
  frame=single,
  fontsize=\relscale{.666},
  fontfamily=courier,
  framerule=.2mm,
  framesep=.7mm,
  numbers=left,
  xleftmargin=4mm,
  numbersep=.25mm,
  firstnumber=last
}
\input{pygments}

\newcounter{lstnocpp}
\newcounter{lstnopyt}
\newcounter{lstnofor}

\setcounter{lstnocpp}{-1}
\setcounter{lstnopyt}{-1}
\setcounter{lstnofor}{-1}

\newcounter{linenocpp}
\newcounter{linenopyt}
\newcounter{linenofor}

\setcounter{linenocpp}{0}
\setcounter{linenopyt}{0}
\setcounter{linenofor}{0}

\newcommand*\FancyVerbStartString{}
\newcommand*\FancyVerbStopString{}

\newcommand{\codecpp}[4]{%
  \addtocounter{lstnocpp}{1}%
  \renewcommand*\FancyVerbStartString{\PY{c+c1}{//#2}}%
  \renewcommand*\FancyVerbStopString{\PY{c+c1}{//#3}}%
  \setcounter{FancyVerbLine}{\thelinenocpp}%
  \fvset{label={listing~C.\thelstnocpp~(C++)},rulecolor=\color{black},stepnumber=#4}%
  \input{#1}%
  \setcounter{linenocpp}{\value{FancyVerbLine}}%
}
\newcommand{\codepyt}[4]{%
  \addtocounter{lstnopyt}{1}%
  \renewcommand*\FancyVerbStartString{\PY{c}{\PYZsh{}#2}}
  \renewcommand*\FancyVerbStopString{\PY{c}{\PYZsh{}#3}}
  \setcounter{FancyVerbLine}{\thelinenopyt}%
  \fvset{label={listing~P.\thelstnopyt~(Python)},rulecolor=\color{blue},stepnumber=#4}%
  \input{#1}%
  \setcounter{linenopyt}{\value{FancyVerbLine}}%
}
\newcommand{\codefor}[4]{%
  \addtocounter{lstnofor}{1}%
  \renewcommand*\FancyVerbStartString{\PY{c}{!#2}}
  \renewcommand*\FancyVerbStopString{\PY{c}{!#3}}
  \setcounter{FancyVerbLine}{\thelinenofor}%
  \fvset{label={listing~F.\thelstnofor~(Fortran)},rulecolor=\color{red},stepnumber=#4}%
  \input{#1}%
  \setcounter{linenofor}{\value{FancyVerbLine}}%
}

\newcommand{\prog}[1]{{\rm\bf#1}}

\journal{Computer Physics Communications}

\begin{document}
    \linenumbers

    \title{
      Formula translation in C++, Python and modern Fortran: a~case~study~of~the~language~choice tradeoffs
    }

    \author[1]{Sylwester Arabas}
    \author[1]{Dorota Jarecka}
    \author[1]{Anna Jaruga}
    \author[2]{Maciej Fija≈Çkowski}

    \affil[1]{Institute of Geophysics, Faculty of Physics, University of Warsaw}
    \affil[2]{PyPy Team}

    \correspondence{Sylwester Arabas (sarabas@igf.fuw.edu.pl)}
    \runningauthor{Arabas, Jarecka et al.}
    \runningtitle{Formula translation in C++, Python \& Fortran}

    \maketitle

    \begin{abstract}
        Three object-oriented implementations of a prototype solver of the advection equation are introduced.
        The presented programs are based on Blitz++ (C++), NumPy (Python), and Fortran's built-in array containers.
        The solvers constitute implementations of the Multidimensional Positive-Definite 
          Advective Transport Algorithm (MPDATA).
        The introduced codes serve as examples for how the application of 
          object-oriented programming (OOP) techniques allows to reproduce the mathematical notation 
          used in the literature within the program code.
        A discussion on the tradeoffs of the programming language choice is presented.
        The main angles of comparison are code brevity and syntax clarity
          (and hence maintainability and auditability) as well as performance.
        All performance tests are carried out using free and open-source compilers.
        In the case of Python, a significant performance gain is observed when switching from the standard 
          interpreter (CPython) to the PyPy implementation of Python.
        Entire source code of all three implementations is embedded in the text and is licensed
          under the terms of the GNU GPL license. 
    \end{abstract}

%    \begin{keyword}
%      object-oriented programming, advection equation, MPDATA, C++, Fortran, Python
%    \end{keyword}

  \introduction

  Object oriented programming (OOP) {\em ''has become recognised as the almost unique successful 
    paradigm for creating complex software''} \citep[][Sec.~1.3]{Press_et_al_2007}.
  It is intriguing that, while the quoted statement comes from the very book subtitled 
   {\em The Art of Scientific Computing}, hardly any (if not none) of the currently operational 
    weather and climate prediction systems - flagship examples of complex scientific software - 
    make extensive use of OOP techniques\footnote{
  Fortran has been the language of choice in oceanic \citep{Griffies_et_al_2000}, 
    weather-prediction \citep{Sundberg_2009} and Earth system \citep{Legutke_2012} modelling, 
    and none of its 20-century editions were object-oriented languages \citep[see e.g.][for discussion]{Norton_et_al_2007}}.

  Application of OOP techniques in development of numerical modelling software may help to:
  \begin{enumerate}[label=(\roman*), leftmargin=*, widest=ii]
    \item{maintain modularity and separation of program logic layers (e.g. separation of
      numerical algorithms, parallelisation mechanisms, data input/output, error handling and
      the description of physical processes); and}
    \item{{\bf shorten and simplify the source code and improve its readability by reproducing within 
      the program logic the mathematical notation used in the literature}.}
  \end{enumerate}
  The first application is attainable, yet arguably cumbersome, with procedural programming.
  The latter, virtually impossible to obtain with procedural programming, is the focus of this paper.
  The importance of reproducing the mathematical notation in the code lays primarily
    in the fact that code readability and brevity \citep[and not the language choice itself,][]{Seeley_2004}
    significantly contribute to code maintainability \citep{Wilson_et_al_2012}.
  Code maintainability, in turn, plays a vital role in community programming efforts 
    and hence geoscientific model development in particular.

  The key aim of this paper is to show how OOP techniques can be used to faithfully
    reproduce within the code what can be referred to as {\em blackboard abstractions} \citep{Rouson_et_al_2012}.
  For this purpose, a sample implementation of a numerical scheme for solving
    the advection equation is introduced in in C++, Python and modern Fortran --
    OOP languages commonly used in scientific computing \citep[see e.g.][chapt.~8]{Einarsson_2005}. 
  Presented benchmark tests, although quite simplistic, together with the experience gained 
    from the development of codes in three different
    languages provide a basis for discussion on the tradeoffs of programming language choice.
  The discussion concerns in principle the development of finite-difference solvers for 
    partial differential equations, but is likely applicable to some extent to the scientific software in general.

  All three programs include an equally structured implementation of the two-dimensional version of the 
    Multidimensional Positive Definite Advective Transport Algorithm \citep[MPDATA;][]{Smolarkiewicz_1984}.
  MPDATA is an example of a numerical procedure used in weather, climate, ocean and solar simulation systems
    \citep[e.g.][respectively]{Ziemianski_et_al_2011,Abiodun_et_al_2011,Ezer_et_al_2002,Charbonneau_and_Smolarkiewicz_2013}.
  Even in its most basic form presented herein, MPDATA is complex enough to contain
    a wide range of mathematical abstractions that can be represented using OOP constructs, 
    yet it is simple enough to allow inclusion of the entire source code within the paper text.
  All relevant MPDATA formul\ae~are given in the text alongside corresponding code fragments
    allowing comparison of the relevant syntax with the mathematical notation.
  In compliance with the article focus, these formul\ae~are presented without derivation or detailed discussion
    \citep[see][for a recent review of MPDATA-based techniques including an introductory description 
    of the algorithm and an exhaustive list of references]{Smolarkiewicz_2006}.

  The paper is structured as follows.
  In section~\ref{sec:impl} we introduce the three implementations
    briefly describing the algorithm itself and
    discussing where and how the OOP techniques may be applied in its implementation.
  Subsections \ref{sec:array}-\ref{sec:solver} describe all three implementations,
    while subsequent sections \ref{sec:cyclic}-\ref{sec:example} cover discussion of C++ code only.
  The relevant parts of Python and Fortran codes do not differ significantly, and for readability reasons 
    are presented in appendices \ref{app:P} and \ref{app:F}, respectively.
  Section~\ref{sec:perf} of this paper covers performance evaluation of the three implementations.
  Section~\ref{sec:tradeoffs} covers discussion of the tradeoffs of the programming language choice.
  Section~\ref{sec:concl} section closes the article with a brief summary.
  Those readers not interested in technical details may wish to skip to section~\ref{sec:perf} or
    \ref{sec:tradeoffs}.

  The entire code is licensed under the terms of the GNU General Public License version 3 \citep{GPLv3}.
  All listings include line numbers printed to the left of the source code, with separate numbering for
    C++ (listings prefixed with C, black frame),
  \codecpp{code-cpp-listings.hpp}{listing00}{listing01}{1}
    Python (listings prefixed with P, blue frame) and
  \codepyt{code-pyt-listings.py}{listing00}{listing01}{1}
    Fortran (listings prefixed with F, red frame).
  \codefor{code-for-listings.f}{listing00}{listing01}{1}
  Programming language constructs when inlined in the text are 
    typeset in bold, e.g. \prog{GOTO 2}.

  \section{Implementation}\label{sec:impl}

  Double precision floating-point format is used in all three implementations.
  The codes begin with the following definitions:
  \codecpp{code-cpp-listings.hpp}{listing01}{listing02}{1}
  \codepyt{code-pyt-listings.py}{listing01}{listing02}{1}
  \codefor{code-for-listings.f}{listing01}{listing02}{1}
  which provide a convenient way of switching to different precision.

  All codes are structured in a way allowing compilation of the code 
    in exactly the same order as presented in the text within one source file,
    hence every Fortran listing contains definition of a separate module.

  The language syntax and OOP nomenclature are used without introduction in the paper,
    for an overview of OOP in context of C++, Python and Fortran, consult for example
    \citep[][Part~II]{Stroustrup_2000}, \citep[][Chapter~5]{Pilgrim_2004} and
    \citep[][Chapter~11]{Markus_2012}, respectively.

  \subsection{Array containers}\label{sec:array}

  MPDATA is a solver for systems of advection equations of the following form:
  \begin{equation}\label{eq:adv}
    \input{formulae_adv}
  \end{equation}
  that describe evolution of a scalar field $\psi$ transported by the fluid flow with velocity $\vec{v}$.
  Solution of equation (\ref{eq:adv}) using MPDATA implies discretisation onto a grid of the $\psi$ and 
    the Courant number $\vec{C}=\vec{v}\cdot\frac{\Delta t}{\Delta x}$ fields, where $\Delta t$ is the 
    solver timestep and $\Delta x$ is the grid spacing.

  Presented C++ implementation of MPDATA is built upon the Blitz++ 
    library\footnote{Blitz++ is a C++ class library for scientific computing which uses the expression templates technique to achieve high performance, see \url{http://sf.net/projects/blitz/}}.
  Blitz offers object-oriented representation of n-dimensional arrays,
    and array-valued mathematical expressions.
  In particular, it offers loop-free notation for array arithmetics
    that does not incur creation of intermediate temporary objects.
  Blitz++ is a header-only library\footnote{Blitz++ requires linking with \prog{libblitz} if debugging mode is used} -- to use it, it is enough to include the appropriate header file,
    and optionally expose the required classes to the present namespace:
  \codecpp{code-cpp-listings.hpp}{listing02}{listing03}{1}
  Here \prog{arr\_t}, \prog{rng\_t} and \prog{idx\_t} serve as alias identifiers 
    and are introduced in order to shorten the code.

  The power of Blitz++ comes from the ability to express array expressions as objects.
  In particular, it is possible to define a function that returns an array expression;
    i.e. not the resultant array, but an object representing a ,,recipe'' defining the operations
    to be performed on the arguments.
  As a consequence, the return types of such functions become unintelligible.
  Luckily, the \prog{auto} return type declaration from the C++11 standard allows to simplify the code significantly,
    even more if used through the following preprocessor macro:
  \codecpp{code-cpp-listings.hpp}{listing03}{listing04}{1}
  The call to \prog{blitz::safeToReturn()} function is included in order to ensure that
    all arrays involved in the expression being returned continue to exist in the
    caller scope.
  For example, definition of a function returning its array-valued argument doubled, reads:
    \prog{auto~f(arr\_t~x)~return\_macro(2*x)}.
  This is the only preprocessor macro defined herein.

  For the Python implementation of MPDATA the NumPy\footnote{NumPy is a Python package
    for scientific computing offering support for multi-dimensional arrays and a library
    of numerical algorithms, see \url{http://numpy.org/}} package is used.
  In order to make the code compatible with both the standard CPython
    as well as the alternative PyPy implementation of Python \citep[][]{Bolz_et_al_2011},
    the Python code includes the following sequence of \prog{import} statements:
  \codepyt{code-pyt-listings.py}{listing02}{listing03}{1}
  First, the PyPy's built-in NumPy implementation named \prog{numpypy} is imported if applicable (i.e. if running PyPy), 
    and the lazy evaluation mode is turned on through the \prog{set\_invalidation(False)} call.
  PyPy's lazy evaluation obtained with the help of a just-in-time compiler enables to achieve
    an analogous to Blitz++ temporary-array-free handling of array-valued expressions 
    (see discussion in section~\ref{sec:perf}).
  Second, to match the settings of C++ and Fortran compilers used herein, the NumPy package is instructed 
    to ignore any floating-point errors, if such an option
    is available in the interpreter\footnote{\prog{numpy.seterr()} is not supported in PyPy as of version 1.9}.
  The above lines conclude all code modifications that needed to be added in order to run
    the code with PyPy.

  Among the three considered languages only Fortran is equipped with built-in
    array handling facilities of practical use in high-performance computing. 
  Therefore, there is no need for using an external package as with C++ and Python.
  Fortran array-handling features are not object-oriented, though.

  \subsection{Containers for sequences of arrays}\label{sec:sequence}

  As discussed above, discretisation in space of the scalar field $\psi(x,y)$ into its $\psi_{[i,j]}$ 
    grid representation requires floating-point array containers.
  In turn, discretisation in time requires a container class for storing
    sequences of such arrays, i.e. \{$\psi^{[n]}$, $\psi^{[n+1]}$\}.
  Similarly the components of the vector field $\vec{C}$ are in fact a \{$C^{[x]}$, $C^{[y]}$\} 
    array sequence.
 
  Using an additional array dimension to represent the sequence elements is not considered for two reasons.
  First, the $C^{[x]}$ and $C^{[y]}$ arrays constituting the sequence have different sizes
    (see discussion of the Arakawa-C grid in section~\ref{sec:grid}).
  Second, the order of dimensions would need to be different for different languages to assure that
    the contiguous dimension is used for one of the space dimensions and not for time levels.

  In the C++ implementation the Boost\footnote{
    Boost is a free and open-source collection of peer-reviewed C++ libraries available at \url{http://www.boost.org/}.
    Several parts of Boost have been integrated into or inspired new additions to the C++ standard.
  } \prog{ptr\_vector} class is used to represent sequences of Blitz++ arrays 
    and at the same time to handle automatic freeing of dynamically allocated memory.
  The \prog{ptr\_vector} class is further customised by defining a derived structure which element-access \prog{[~]} 
    operator is overloaded with a modulo variant:
  \codecpp{code-cpp-listings.hpp}{listing04}{listing05}{1}
  Consequently the last element of any such sequence may be accessed at index \prog{-1}, the last but one at \prog{-2}, 
    and so on.

  In the Python implementation the built-in \prog{tuple} type is used to store sequences of NumPy arrays.
  Employment of negative indices for handling from-the-end addressing of elements
    is a built-in feature of all sequence containers in Python.

  Fortran does not feature any built-in sequence container capable of storing arrays, 
    hence a custom \prog{arrvec\_t} type is introduced:
  \codefor{code-for-listings.f}{listing02}{listing03}{1}
  The \prog{arr\_t} type is defined solely for the purpose of overcoming the limitation 
    of lack of an array-of-arrays construct, and its only member field is a two-dimensional array.
  An array of \prog{arr\_t} is used hereinafter as a container for sequences of arrays.

  The \prog{arrptr\_t} type is defined solely for the purpose of overcoming Fortran's limitation
    of not supporting allocatables of pointers.
  \prog{arrptr\_t}'s single member field is a pointer to an instance of \prog{arr\_t}.
  Creating an allocatable of \prog{arrptr\_t}, instead of 
    a multi-element pointer of \prog{arr\_t}, ensures automatic memory deallocation.

  Type \prog{arrptr\_t} is used to implement the from-the-end addressing of elements in \prog{arrvec\_t}.
  The array data is stored in the \prog{arrs} member field (of type \prog{arr\_t}).
  The \prog{at} member field (of type \prog{arrptr\_t}) stores pointers to the elements of \prog{arrs}. 
  \prog{at} has double the length of \prog{arrs} and is initialised in a cyclic manner so that
    the \prog{-1} element of \prog{at} points to the last element of \prog{arrs}, and so on.
  Assuming \prog{psi} is an instance of \prog{arrptr\_t}, the \prog{(i,j)} element of the \prog{n}-th array in \prog{psi}
    may be accessed with\\ \prog{psi\%at( n )\%p\%a( i, j )}.

  The \prog{ctor(n)} method initialises the container for a given number of elements \prog{n}.
  The \prog{init(n,i,j)} method initialises the \prog{n}-th element of the container with 
    a newly allocated 2D array spanning indices \prog{i(1)}:\prog{i(2)}, 
    and \prog{j(1)}:\prog{j(2)} in the first, and last dimensions respectively\footnote{In Fortran, when an array
    is passed as a function argument its base is locally set to unity, regardless of the setting
    at the caller scope.}.

  \subsection{Staggered grid}\label{sec:grid}

  \begin{figure}[h!]
  \center
  \begin{tikzpicture}
    \coordinate (Origin)   at (0,0);
    \coordinate (XAxisMin) at (-2.5,0);
    \coordinate (XAxisMax) at (3,0);
    \coordinate (YAxisMin) at (0,-2.5);
    \coordinate (YAxisMax) at (0,3);
    \draw [thin, gray,-latex] (XAxisMin) -- (XAxisMax);% Draw x axis
    \draw [thin, gray,-latex] (YAxisMin) -- (YAxisMax);% Draw y axis

    \clip (-2.5,-2.5) rectangle (2.5cm,2.5cm); % Clips the picture...
    \draw[style=help lines,dashed] (-14,-14) grid[step=2cm] (14,14);
          % Draws a grid in the new coordinates.
          %\filldraw[fill=gray, fill opacity=0.3, draw=black] (0,0) rectangle (2,2);
              % Puts the shaded rectangle
    \foreach \x in {-7,-6,...,7}{% Two indices running over each
      \foreach \y in {-7,-6,...,7}{% node on the grid we have drawn 
        \node[draw,circle,inner sep=2pt,fill] at (2*\x,2*\y) {};
            % Places a dot at those points
      }
    }
    \draw [black] (0,0) -- (0,0) node [below right] {$\!\psi_{[i,j]}$};
    \draw [black] (-2,0) -- (-2,0) node [below right] {$\!\psi_{[i-1,j]}$};
    \draw [black] (0,2) -- (0,2) node [below right] {$\!\psi_{[i,j+1]}$};

    \draw [ultra thick,-latex,red] (.8,0) -- (1.2,0) node [above right] {$\!\!\!\!\!\!\!\!\!\!C^{[x]}_{[i+\phlf,j]}$};
    \draw [ultra thick,-latex,red] (-1.2,0) -- (-.8,0) node [above right] {$\!\!\!\!\!\!\!\!\!\!C^{[x]}_{[i\mhlf,j]}$};
    \draw [ultra thick,-latex,red] (.8,2) -- (1.2,2) node [above] {};
    \draw [ultra thick,-latex,red] (-1.2,2) -- (-.8,2) node [above] {};
    \draw [ultra thick,-latex,red] (.8,-2) -- (1.2,-2) node [above] {};
    \draw [ultra thick,-latex,red] (-1.2,-2) -- (-.8,-2) node [above] {};

    \draw [ultra thick,-latex,red] (0,.8) -- (0,1.2) node [above] {};
    \draw [ultra thick,-latex,red] (0,-1.2) -- (0,-.8) node [below right] {$C^{[y]}_{[i,j\mhlf]}$};
    \draw [ultra thick,-latex,red] (-2,.8) -- (-2,1.2) node [above] {};
    \draw [ultra thick,-latex,red] (-2,-1.2) -- (-2,-.8) node [above] {};
    \draw [ultra thick,-latex,red] (2,.8) -- (2,1.2) node [above] {};
    \draw [ultra thick,-latex,red] (2,-1.2) -- (2,-.8) node [above] {};
  \end{tikzpicture}
  \caption{\label{fig:grid}
    A schematic of the Arakawa-C grid.
  }
  \end{figure}
  The so-called Arakawa-C staggered grid \citep{Arakawa_and_Lamb_1977} depicted in Figure~\ref{fig:grid}
    is a natural choice for MPDATA.
  As a consequence, the discretised representations of the $\psi$ scalar field, and each 
    component of the ${\vec{C}=\vec{v}\cdot\frac{\Delta t}{\Delta x}}$ vector field 
    in eq.~(\ref{eq:adv}) are defined over different grid point locations.
  In mathematical notation this can be indicated by usage of fractional indices, e.g.
    $C^{[x]}_{[i\mhlf,j]}$, $C^{[x]}_{[i+\phlf,j]}$, $C^{[y]}_{[i,j\mhlf]}$ and $C^{[y]}_{[i,j+\phlf]}$
    to depict the grid values of the ${\vec{C}}$ vector components surrounding $\psi_{[i,j]}$.
  However, fractional indexing does not have a built-in counterpart in any of the
    employed programming languages.
  A desired syntax would translate \prog{$i-\phlf$} to \prog{$i-1$} and
    \prog{$i+\phlf$} to \prog{$i$}.
  OOP offers a convenient way to implement such notation
    by overloading the \prog{+} and \prog{-} operators for objects representing array indices. 

  In the C++ implementation first a global instance \prog{h} of an empty structure 
    \prog{hlf\_t} is defined, and then the plus and minus operators for \prog{hlf\_t} and \prog{rng\_t} are overloaded:
  \codecpp{code-cpp-listings.hpp}{listing05}{listing06}{1}
  This way, the arrays representing vector field components can be indexed using
    \prog{(i+h,j)}, \prog{(i-h,j)} etc. where \prog{h}~represents the half.

  In NumPy in order to prevent copying of array data during slicing one needs to operate on the
    so-called array views.
  Array views are obtained when indexing the arrays with objects of the Python's
    built-it \prog{slice} type (or tuples of such objects in case of multi-dimensional arrays).
  Python forbids overloading of operators of built-in types such as \prog{slices}, 
    and does not define addition/subtraction operators for \prog{slice} and \prog{int} pairs.
  Consequently, a custom logic has to be defined not only for fractional indexing,
    but also for shifting the slices by integer intervals ($i\pm1$).
  It is implemented here by declaring a \prog{shift} class with the adequate operator overloads:
  \codepyt{code-pyt-listings.py}{listing03}{listing04}{1}
    and two instances of it to represent unity and half
    in expressions like \prog{i+one}, \prog{i+hlf}, where \prog{i} is an instance of \prog{slice}
    \footnote{\label{fnt:slice}One could argue that not using an own implementation of a slice-representing class
    in NumPy is a design flaw -- being able to modify behaviour of a hypothetical numpy.slice class 
    through inheritance would allow to implement the same behaviour as obtained in listing P.3 without the need to represent 
    the unity as a separate object}:
  \codepyt{code-pyt-listings.py}{listing04}{listing05}{1}

  In the Fortran implementation fractional array indexing is obtained through
    definition and instantiation of an object representing the half, and having appropriate
    operator overloads:
  \codefor{code-for-listings.f}{listing03}{listing04}{1}

  \subsection{Halo regions}

  The MPDATA formul\ae~defining $\psi^{[n+1]}_{[i,j]}$ as a function of $\psi^{[n]}_{[i,j]}$
    (discussed in the following sections) feature terms such as $\psi_{[i-1,j-1]}$.
  One way of assuring validity of these formul\ae~on the edges of the domain (e.g. for i=0) 
    is to introduce the so-called halo region surrounding the domain.
  The method of populating the halo region with data depends on the boundary condition type.
  Employment of the halo-region logic implies repeated usage of array range 
    extensions in the code such as $i \leadsto i \pm halo$.

  An \prog{ext()} function is defined in all three implementation, in order to simplify 
    coding of array range extensions:
  \codecpp{code-cpp-listings.hpp}{listing06}{listing07}{1}
  \codepyt{code-pyt-listings.py}{listing05}{listing06}{1}
  \codefor{code-for-listings.f}{listing04}{listing05}{1}
  Consequently, a range depicted by $i\pm1/2$ may be expressed in the code as \prog{ext(i, h)}.
  In all three implementations the \prog{ext()} function accept the second
    argument to be an integer or a ''half'' (cf. section \ref{sec:grid}).

  \subsection{Array index permutations}\label{sec:pi}
  Hereinafter, the $\pi_{a,b}^{d}$ symbol is used to denote a  
    cyclic permutation of an order $d$ of a set $\{a,b\}$.
  It is used to generalise the MPDATA formul\ae~into multiple dimensions
    using the following notation:
  \begin{equation*}\label{eq:pi}
    \input{formulae_pi}
  \end{equation*}

  Blitz++ ships with the \prog{RectDomain} class (aliased here as \prog{idx\_t}) 
    for specifying array ranges in multiple dimensions.
  The $\pi$ permutation is implemented in C++ as a function \prog{pi()}
    returning an instance of \prog{idx\_t}.
  In order to ensure compile-time evaluation, the permutation order is passed 
    via the template parameter \prog{d}
    (note the different order of \prog{i} and \prog{j} arguments in the two template specialisations):
  \codecpp{code-cpp-listings.hpp}{listing07}{listing08}{1}

  NumPy uses tuples of slices for addressing multi-dimensional array with a
    single object.
  Therefore, the following definition of function \prog{pi()} suffices to represent $\pi$:
  \codepyt{code-pyt-listings.py}{listing06}{listing07}{1}
  
  In the Fortran implementation \prog{pi()} returns a pointer to the array elements specified
    by \prog{i} and \prog{j} interpreted as (i,j) or
    (j,i) depending on the value of the argument \prog{d}.
  In addition to \prog{pi()}, a helper \prog{span()} function returning the 
    length of one of the vectors passed as argument is defined:
  \codefor{code-for-listings.f}{listing05}{listing06}{1}
  The \prog{span()} function is used to shorten the declarations of arrays to be returned 
    from functions in the Fortran implementation (see listings F.11 and F.17--F.20).

  It is worth noting here that the C++ implementation of \prog{pi()} is
    branchless thanks to employment of template specialisation.
  With Fortran one needs to rely on compiler optimisations to eliminate the conditional expression
    within \prog{pi()} that depends on value of \prog{d} which is always known 
    at compile time.

  \subsection{Prototype solver}\label{sec:solver}

  The tasks to be handled by a prototype advection equation solver proposed herein are:
  \begin{enumerate}[label=(\roman*), leftmargin=*, widest=iii]
    \item{storing arrays representing the $\psi$ and $\vec{C}$ fields and any required housekeeping data,}
    \item{allocating and deallocating the required memory,}
    \item{providing access to the solver state,}
    \item{performing the integration by invoking the advection-operator and
      boundary-condition handling routines.}
  \end{enumerate}
  In the following C++ definition of the \prog{solver} structure, task (i) is represented with the definition of the structure
    member fields; task (ii) is split between the \prog{solver}'s constructor and the destructors of \prog{arrvec\_t};
    task (iii) is handled by the accessor methods; task (iv) is handled within the \prog{solve} method:
  \codecpp{code-cpp-listings.hpp}{listing08}{listing09}{1}
  The \prog{solver} structure is an abstract definition (containing a pure virtual method) 
     requiring its descendants to implement at least
     the \prog{advop()} method which is expected to fill \prog{psi[n+1]} with an updated (advected)
     values of \prog{psi[n]}.
  The two template parameters \prog{bcx\_t} and \prog{bcy\_t} allow the solver to operate with 
    any kind of boundary condition structures that fulfil the requirements implied by the calls to the 
    methods of \prog{bcx} and \prog{bcy}, respectively.

  The donor-cell and MPDATA schemes both require only the previous state of an advected field
    in order to advance the solution.
  Consequently, memory for two time levels ($\psi^{[n]}$ and $\psi^{[n+1]}$) is allocated in the
    constructor.
  The sizes of the arrays representing the two time levels of $\psi$ 
    are defined by the domain size ({\em nx}$~\times$~{\em ny}) plus the halo region.
  The size of the halo region is an argument of the constructor.
  The \prog{cycle()} method is used to swap the time levels without copying any data.

  The arrays representing the $C^{[x]}$ and $C^{[y]}$ components of $\vec{C}$,
    require ({\em nx+1})~$\times$~{\em ny} 
    and {\em nx}$~\times$~({\em ny+1}) elements, respectively
    (being laid out on the Arakawa-C staggered grid).
  
  Python definition of the \prog{solver} class follows closely the C++ structure definition:
  \codepyt{code-pyt-listings.py}{listing07}{listing08}{1}
  The key difference stems from the fact that, unlike Blitz++, NumPy does not allow an array
    to have arbitrary index base -- in NumPy the first element is always addressed with 0.
  Consequently, while in C++ (and Fortran) the computational domain is chosen to start at (i=0, j=0)
    and hence a part of the halo region to have negative indices, in Python the halo region starts 
    at (0,0)\footnote{The reason to allow the domain to begin at an arbitrary index
    is mainly to ease debugging in case the code would be used in parallel computations
    using domain decomposition where each subdomain could have its own index base corresponding to
    the location within the computational domain}.
  However, since the whole halo logic is hidden within the solver, such details are not exposed to the
    user.
  The \prog{bcx} and \prog{bcy} boundary-condition specifications are passed to the solver through
    constructor-like \prog{\_\_init\_\_()} method as opposed to template parameters in C++.

  The above C++ and Python prototype solvers in principle allow to operate with any boundary condition
    objects that implement methods called from within the solver.
  This requirement is checked at compile-time in the case of C++, and at run-time in the case of Python.
  In order to obtain an analogous behaviour with Fortran, it is required to
    define, prior to definition of a solver type, 
    an abstract type with deferred procedures having abstract interfaces 
    \citep[sic!, see Table 2.1 in][for a summary of approximate correspondence of OOP 
      nomenclature between Fortran and C++]{Rouson_et_al_2012}:
  \codefor{code-for-listings.f}{listing06}{listing07}{1}
  Having defined the abstract type for boundary-condition objects, 
    a definition of a solver class following closely the C++ and Python counterparts may be provided:
  \codefor{code-for-listings.f}{listing07}{listing08}{1}

  \subsection{Periodic boundaries (C++)}\label{sec:cyclic}

  From this point, only C++ implementation is explained in the main text. 
  The Python and Fortran implementations are included in appendices A and B.  

  The solver definition described in section~\ref{sec:solver} requires a given
    boundary condition object to implement a \prog{fill\_halos()} method.
  An implementation of periodic boundary conditions in C++ is provided in the following listing:
  \codecpp{code-cpp-listings.hpp}{listing09}{listing10}{1}

  As hinted by the member field names, the \prog{fill\_halos()} methods
    fill the left/right halo regions with data from the right/left edges of the domain.
  Thanks to employment of the function \prog{pi()} described in section~\ref{sec:pi}
    the same code may be applied in any dimension (here being a template parameter).

  Listings P.8 and F.8 contain the Python and Fortran counterparts to listing C.9.

  \subsection{Donor-cell formul\ae~(C++)}\label{sec:donor}
  MPDATA is an iterative algorithm in which each iteration takes the form of the 
    so-called donor-cell formula (which itself is a first-order advection scheme).

  MPDATA and donor-cell are explicit forward-in-time algorithms -- they allow to predict $\psi^{[n+1]}$ as a
    function of $\psi^{[n]}$ where $n$ and $n+1$ denote two adjacent time levels.
  The donor-cell scheme may be written as \citep[eq. 2 in][]{Smolarkiewicz_1984}:
  \begin{equation}\label{eq:donor}
    \input{formulae_donor}
  \end{equation}
  where $N$ is the number of dimensions, 
    and F is the so-called flux function \citep[][eq.~3]{Smolarkiewicz_1984}:
  \begin{equation}\label{eq:donor:F}
    \input{formulae_donor-F}
  \end{equation}

  \noindent The flux function takes the following form in C++:
  \codecpp{code-cpp-listings.hpp}{listing10}{listing11}{1}

  \noindent 
  Equation~\ref{eq:donor} is split into the terms under the summation 
    (effectively the 1-dimensional donor-cell formula):
  \codecpp{code-cpp-listings.hpp}{listing11}{listing12}{1}

  \noindent and the actual two-dimensional donor-cell formula:

  \codecpp{code-cpp-listings.hpp}{listing12}{listing13}{1}

  Listings P.9-P11 and F.9-F.13 contain the Python and Fortran counterparts to listings C.12-C.15.

  \subsection{Donor-cell solver (C++)}\label{sec:donorcell_solver}
  
  As mentioned in the previous section, the donor-cell formula
    constitutes an advection scheme, hence we may use it to create
    a \prog{solver\_donorcell} implementation of the abstract \prog{solver} class: 
  \codecpp{code-cpp-listings.hpp}{listing13}{listing14}{1}
  The above definition is given as an example only.
  In the following sections an MPDATA solver of the same structure is defined.

  Listings P.12 and F.14 contain the Python and Fortran counterparts to listing C.16.

  \subsection{MPDATA formul\ae~(C++)}\label{sec:mpdata}

  MPDATA introduces corrective steps to the algorithm defined by equation~\ref{eq:donor} and \ref{eq:donor:F}.
  Each corrective step is a donor-cell step (eq.~\ref{eq:donor}) with the Courant number
    fields corresponding to the MPDATA antidiffusive velocities of the following 
    form \citep[eqs~13,~14~in][]{Smolarkiewicz_1984}:
  \begin{equation}\label{eq:antidiff1}
    \input{formulae_antidiff1}
  \end{equation}
  where $\psi$ and $C$ represent values from the previous iteration and where:
  \begin{equation}\label{eq:antidiff2}
    \input{formulae_antidiff2}
  \end{equation}
  For positive-definite $\psi$, the $A$ and $B$ terms take the 
  following form\footnote{
    Since $\psi\ge0$, $|A|\le1$ and $|B|\le1$. 
    See \citet[Sec. 4.2]{Smolarkiewicz_2006} for description of adaptation of the 
    formul\ae~for advection of fields of variable sign
  }:
  \begin{equation}\label{eq:A}
    \input{formulae_A}
  \end{equation}
  \begin{equation}\label{eq:B}
    \input{formulae_B}
  \end{equation}

  If the denominator in equations \ref{eq:A} or \ref{eq:B} equals zero for a given {\em i} and {\em j}, 
    the corresponding $A_{[i,j]}$ and $B_{[i,j]}$ are set to zero what may be conveniently 
    represented with the \prog{where} construct (available in all three considered languages):
  \codecpp{code-cpp-listings.hpp}{listing14}{listing15}{1}

  The $A$ term defined in equation \ref{eq:A} takes the following form:
  \codecpp{code-cpp-listings.hpp}{listing15}{listing16}{1}

  The $B$ term defined in equation \ref{eq:B} takes the following form:
  \codecpp{code-cpp-listings.hpp}{listing16}{listing17}{1}

  Equation \ref{eq:antidiff2} takes the following form:
  \codecpp{code-cpp-listings.hpp}{listing17}{listing18}{1}

  Equation \ref{eq:antidiff1} take the following form:
  \codecpp{code-cpp-listings.hpp}{listing18}{listing19}{1}

  Listings P.13-P.17 and F.15-F.21 contain the Python and Fortran counterparts to listing C.16-C.22.

  \subsection{MPDATA solver (C++)}\label{sec:mpdatasolver}

  An MPDATA solver may be now constructed by inheriting from \prog{solver} class
    with the following definition in C++:
  \codecpp{code-cpp-listings.hpp}{listing19}{listing20}{1}
  The array of sequences of temporary arrays \prog{tmp} allocated in the constructor
    is used to store the antidiffusive velocities from the present and optionally 
    previous timestep (if using more than two iterations). 

  The \prog{advop()} method controlls the MPDATA iterations within one timestep.
  The first (step = 0) iteration of MPDATA is an unmodified donor-cell step (compare listing C.15).
  Subsequent iterations begin with calculation of the antidiffusive Courant fields using 
    formula \ref{eq:antidiff1}.
  In order to calculate values spanning an (i\mhlf~... i+\phlf) range using a formula
    for $C_{[i+\phlf,\ldots]}$ only, the formula is evaluated using extended
    index ranges \prog{im} and \prog{jm}.
  In the second (step=1) iteration the uncorrected Courant field (\prog{C\_unco}) points
    to the original \prog{C} field, and the antidiffusive Courant field is written into
    \prog{C\_corr} which points to \prog{tmp[1]}.
  In the third (step=2) iteration \prog{C\_unco} points to \prog{tmp[1]} while \prog{C\_corr}
    points to \prog{tmp[0]}.
  In subsequent iterations \prog{tmp[0]} and \prog{tmp[1]} are alternately swapped.

  Listings P.18 and F.22 contain the Python and Fortran counterparts to listing C.23.
 
  \subsection{Usage example (C++)}\label{sec:example}

  The following listing provides an example of how the MPDATA solver
    defined in section~\ref{sec:mpdatasolver} may be used together
    with the cyclic boundary conditions defined in section~\ref{sec:cyclic}.
  In the example a Gaussian signal is advected in a 2D domain 
    defined over a grid of 24$\times$24 cells.
  The program first plots the initial condition, then performs
    the integration for 75 timesteps with three different 
    settings of the number of iterations used in MPDATA.
  The velocity field is constant in time and space (although it is
    not assumed in the presented implementations).
  The signal shape at the end of each simulation is plotted as well.
  Plotting is done with the help of the gnuplot-iostream library\footnote{gnuplot-iostream
    is a header-only C++ library allowing gnuplot to be controlled from C++, see \url{http://stahlke.org/dan/gnuplot-iostream/}. 
    Gnuplot is a portable command-line driven graphing utility, see \url{http://gnuplot.info/}}.

  The resultant plot is presented herein as Figure~\ref{fig:mpdata}.
  The top panel depicts the initial condition. 
  The three other panels show a snapshot of the field after 75 timesteps.
  The donor-cell solution is characterised by strongest numerical diffusion
    resulting in significant drop in the signal amplitude.
  The signals advected using MPDATA show smaller numerical diffusion with
    the solution obtained with more iterations preserving the signal altitude 
    more accurately.
  In all of the simulations the signal maintains its positive definiteness.
  The domain periodicity is apparent in the plots as the maximum of the signal 
    after 75 timesteps is located near the domain walls.

  Listings P.19 and F.23-F.24 contain the Python and Fortran 
    counterparts to listing C.24 (with the set-up and plotting logic omitted).

  \codecpp{code-cpp-plot.cpp}{listing20}{listing21}{1}

  \begin{figure}
    \includegraphics[height=.9\textheight]{demo}
    \caption{\label{fig:mpdata}
      Plot generated by the program given in listing~C.24.
      The top panel shows initial signal shape (at time t=0).
      The subsequent panels show snapshots of the advected field after 75 timesteps
        from three different simulations: donorcell (or 1 MPDATA iteration), MPDATA
        with two iterations and MPDATA with 44 iterations.
      The colour scale and the wire-frame surface correspond to signal amplitude.
      See section~\ref{sec:example} for discussion.
    }
  \end{figure}

  \section{Performance evaluation}\label{sec:perf}

  The three introduced implementations of MPDATA were tested with the following set-ups 
    employing free and open-source tools:
  \begin{description}
    \item[C++:]{~
      \begin{itemize}
        \item{GCC g++ 4.8.0\footnote{\label{fnt:gcc-snapshot}GNU Compiler Collection packaged in the Debian's gcc-snapshot\_20130222-1} 
          and Blitz++ 0.10}
        \item{LLVM Clang 3.2 and Blitz 0.10}
      \end{itemize}
    }
    \item[Python:]{~
      \begin{itemize}
        \item{CPython 2.7.3 and NumPy 1.7}
        \item{PyPy 1.9.0 with built-in NumPy implementation}
      \end{itemize}
    }
    \item[Fortran:]{~
      \begin{itemize}
        \item{GCC gfortran 4.8.0\textsuperscript{\ref{fnt:gcc-snapshot}}}
      \end{itemize}
    }
  \end{description}
  The performance tests were run on a Debian and an Ubuntu GNU/Linux systems with the above-listed software obtained 
    via binary packages from the distributions' package repositories (most recent package versions at the time of writing).
  The tests were performed on two 64-bit machines equipped with
    an AMD Phenom\textsuperscript{\texttrademark} II X6 1055T (800 MHz)
    and an Intel\textsuperscript{\textregistered} Core\textsuperscript{\texttrademark}~i5-2467M (1.6 GHz)
    processors.

  For both C++ and Fortran the GCC compilers were invoked with the \prog{-Ofast} and the 
    \prog{-march=native} options.
  The Clang compiler was invoked with the \prog{-O3}, the \prog{-mllvm -vectorize}, the \prog{-ffast-math} 
    and the \prog{-march=native} options.
  The CPython interpreter was invoked with the \prog{-OO} option.

  In addition to the standard Python implementation CPython,
    the Python code was tested with PyPy.
  PyPy is an alternative implementation of Python featuring a just-in-time compiler. 
  PyPy includes an experimental partial reimplementation of NumPy that compiles NumPy expressions into native assembler.
  Thanks to employment of lazy evaluation of array expressions (cf. Sect. \ref{sec:array})
    PyPy allows to eliminate the use of temporary matrices for storing intermediate results,
    and to perform multiple operations on the arrays within a single array index traversal
    \footnote{Lazy evaluation available in PyPy 1.9 has been temporarily removed from PyPy during a refactoring of
      the code. It'll be reinstantiated in the codebase as soon as possible, but past PyPy 2.0 release}.
  Consequently, PyPy allows to overcome the same performance-limiting factors as those addressed by Blitz++, although 
    the underlying mechanisms are different.
  In contrast to other solutions for improving performance of NumPy-based codes such as
    Cython\footnote{see \url{http://cython.org}}, 
    numexpr\footnote{see \url{http://code.google.com/p/numexpr/}} or 
    Numba\footnote{see \url{http://numba.pydata.org/}}, 
    PyPy does not require any modifications to the code.
  Thus, PyPy may serve as a drop-in replacement for CPython ready to be used with 
    previously-developed codes.
  
  The same set of tests was run with all four set-ups.
  Each test set consisted of 16 program runs.
  The test programs are analogous to the example code presented in section~\ref{sec:example}.
  The tests were run with different grid sizes ranging from 64$\times$64 to 2048$\times$2048.
  The Gaussian impulse was advected for $nt=2^{24}/(nx\cdot ny)$ timesteps ($2^{24}$ chosen arbitrarily), 
    in order to assure comparable timing accuracy for all grid sizes.
  Three MPDATA iterations were used (i.e. two corrective steps).
  The initial condition was loaded from a text file, and the final values were compared at the end of the test
    with values loaded from another text file assuring the same results were obtained with all four set-ups.
  The tests were run multiple times; program start-up, data loading, and output verification times were
    subtracted from the reported values (see caption of Figure~\ref{fig:cpu-eyrie} for details).

  \begin{figure}[t]
    \center
    \includegraphics[height=.45\textwidth,angle=-90]{skua-mem}
    \caption{\label{fig:mem}
      Memory consumption statistics for the test runs described in Section~\ref{sec:perf}
        plotted as a function of grid size.
      Peak resident set size (rss) values reported by the GNU time utility are normalised by the size of
        data that needs to be allocated in the program to store all declared grid-sized arrays.
      Asymptotic values reached at the largest grid sizes are indicative 
        of temporary storage requirements.
    }
  \end{figure}

  Figure \ref{fig:mem} presents a plot of the peak memory use\footnote{The resident set size (rss)
    as reported by GNU time (version 1.7-24)} (identical for both considered CPUs)
    as a function of grid size.
  The plotted values are normalised by the nominal size of all data arrays used in the program
    (i.e. two (nx+2)$\times$(ny+2) arrays representing the two time levels of $\psi$, 
     a (nx+1)$\times$(ny+2) array representing the $C^{[x]}$ component of the Courant number field,
     a (nx+2)$\times$(ny+1) array representing the $C^{[y]}$ component, 
     and two pairs of arrays of the size of $C^{[x]}$ and $C^{[y]}$ for storing the 
     antidiffusive velocities, all composed of 8-byte double-precision floating point numbers).
  Plotted statistics reveal a notable memory footprint of the Python interpreter itself
    for both CPython and PyPy, losing its significance for domains larger than 1024$\times$1024.
  The roughly asymptotic values reached in all four set-ups for grid sizes larger that 1024$\times$1024
    are indicative of the amount of temporary memory used for array manipulation.
  PyPy- and Blitz++-based set-ups consume notably less memory than Fortran and CPython.
  This confirms the effectiveness of the just-in-time compilation (PyPy) and the expression-templates (Blitz++) techniques
    for elimination of temporary storage during array operations.

  \begin{figure}[t]
    \center
    \includegraphics[height=.45\textwidth,angle=-90]{laptok-cpu}
    \caption{\label{fig:cpu-eyrie}
      Execution time statistics for the test runs described in Section~\ref{sec:perf}
        plotted as a function of grid size.
      Values of the total user mode CPU time reported by the GNU time utility are
        normalised by the grid size ($nx \cdot ny$) and the number of timesteps $nt=2^{24}/(nx \cdot ny)$.
      Before normalisation the time reported for an $nt=0$ run for a corresponding
        domain size is subtracted from the values.
      Both the $nt=0$ and $nt=2^{24}/(nx \cdot ny)$ runs are repeated three times and
        only the shortest time is taken into account.
      Results obtained with an Intel\textsuperscript{\textregistered} 
        Core\textsuperscript{\texttrademark} i5 1.6 GHz processor.
    }
  \end{figure}
  \begin{figure}[t]
    \center
    \includegraphics[height=.45\textwidth,angle=-90]{skua-cpu}
    \caption{\label{fig:cpu-skua}
      Same as Fig.~\ref{fig:cpu-eyrie} for an AMD Phenom\textsuperscript{\texttrademark} II 800 MHz processor.
    }
  \end{figure}

  The CPU time statistics presented in Figures \ref{fig:cpu-eyrie} and \ref{fig:cpu-skua} reveal
    minor differences between results obtained with the two different processors.
  Presented results lead to the following observations
    (where by referring to language names, only the results obtained with the herein considered
     program codes, and software/hardware configurations are meant):
  \begin{itemize}
    \item{Fortran gives shortest execution times for any domain size;}
    \item{C++ execution times are less than twice those of Fortran for grids larger than 
      256$\times$256;}
    \item{CPython requires from around 4 to almost 10 times more CPU time than Fortran depending on the grid size;}
    \item{PyPy execution times are in most cases closer to C++ than to CPython.}
  \end{itemize}
  The support for OOP features in gfortran, the NumPy support in PyPy, and the relevant optimisation
    mechanisms in GCC are still in active development and hence the performance with some of the set-ups may 
    likely change with newer versions of these packages. 

  It is worth mentioning, that even though the three implementations are equally structured,
    the three considered languages have some inherent differences influencing the execution times.
  Notably, while Fortran and Blitz++ offer runtime array-bounds and array-shape checks as options
    not intended for use in production binaries, NumPy performs them always.
  Additionally, the C++ and Fortran set-ups may, in principle, benefit from GCC's auto-vectorisation
    features which do not have yet counterparts in CPython or PyPy.
  Finally, Fortran uses different ordering for storing array elements in memory, but since
    all tests were carried out using square grids, this should not have had any impact on the
    performance\footnote{Both Blitz++ and NumPy support Fortran's column-major ordering as well, 
    however this feature is still missing from PyPy's built-in NumPy implementation as of PyPy 1.9}.

  \section{Discussion on the tradeoffs of language choice}\label{sec:tradeoffs}

  \subsection{OOP for blackboard abstractions}

  It was shown in section~\ref{sec:impl} that C++11/Blitz++, Python/NumPy and Fortran 2008
    provide comparable functionalities in terms of matching the blackboard abstractions
    within the program code.
  Taking into account solely the part of code representing particular formul\ae~
    (e.g. listings C.21, P.17, F.20 and equation \ref{eq:antidiff1}) all three
    languages allow to match (or surpass) \LaTeX~in its brevity of formula translation syntax.
  All three languages were shown to be capable of providing mechanisms to compactly represent such abstractions as:
  \begin{itemize}
    \item{loop-free array arithmetics;}
    \item{definitions of functions returning array-valued expressions;}
    \item{permutations of array indices allowing dimension-independent definitions
      of functions (see e.g. listings C.12 and C.13, P.10 and P.11, F.11 and F.12);}
    \item{fractional indexing of arrays corresponding to employment of a staggered grid.}
  \end{itemize}
  
  Making use of features such as loop-free arithmetics not only shortens the code,
    but also enables the compiler or library authors to relieve the user (i.e. scientific programmer)
    from hand-coding optimisations (e.g. loop order choice).
  Hand-coded optimisations -- code rearrangements aimed solely at the purpose of increasing performance --
    were long recognised as having {\em a strong negative impact when debugging
    and maintenance are considered} \citep{Knuth_1974},
    and are generally advised to be avoided \citep[e.g.][section 3.12]{bib_CERNcpp}.

  Three issues specific to Fortran that 
    resulted in employment of a more repetitive or cumbersome syntax than in C++ or Python
    were observed:
  \begin{itemize}
    \item{Fortran does not feature a mechanism allowing to reuse a single piece of code (algorithm)
      with different data types (compare e.g. listings C.6, P.5 and F.4) such as
      templates in C++ and the so-called duck typing in Python;}
    \item{Fortran does not allow function calls to appear on the left hand side
      of assignment (see e.g. how the \prog{ptr} pointers were used as a workaround in the \prog{cyclic\_fill\_halos}
      method in listing F.8);}
    \item{Fortran lacks support for arrays of arrays (cf. Sect. \ref{sec:sequence}).}
  \end{itemize}
  Interestingly, the limitation in extendability via inheritance was found to
    exist partially in NumPy as well (see footnote \ref{fnt:slice}).
  The lack of a counterpart in Fortran to the C++ template mechanism was identified in
    \citep{Cary_et_al_1997}
    as one of the key deficiencies of Fortran when compared with C++ in context 
    of applicability to object-oriented scientific programming.

  \subsection{Performance}
  
  The timing and memory usage statistics presented in figures \ref{fig:mem}-\ref{fig:cpu-skua}
    reveal that no single language/library/compiler set-up 
    corresponded to both shortest execution time and smallest memory footprint.

  One may consider performance measures addressing not only the program efficiency but also 
    the factors influencing the development and maintenance time/cost 
    \citep[of particular importance in scientific computing,][]{Wilson_2006}.
  Taking into account such measures as code length or coding time,
    the Python environment gains significantly \citep[see also discussion in][]{Lin_2012}.
  Presented Python code is shorter than the C++ and Fortran counterparts,
    and is simpler in terms of syntax and usage (see discussion below).

  Employment of the PyPy drop-in replacement for the standard Python implementation brings 
    Python's performance significantly closer to those of C++ and Fortran, in some
    cases making it the least memory consuming set-up.
  Python has already been the language of choice for scientific software projects having code clarity 
    or ease of use as the first requirement \citep[see e.g.][]{Barnes_and_Jones_2011}.
  PyPy's capability to improve performance of unmodified Python code may 
    make Python a favourable choice even if high performance is important, especially
    if a combined measure of performance and development cost is to be considered. 

  \subsection{Ease of use and abuse}

  Using the number of lines of code or the number of distinct language keywords
    needed to implement the MPDATA-based
    solver presented in section \ref{sec:impl} as measures of syntax 
    brevity, Python clearly surpasses its rivals.
  Python was developed with emphasis on code readability and object-orientation.
  Arguably, taking it to the extreme - Python uses line indentation to define 
    blocks of code and treats even single integers as objects.
  As a consequence Python is easy to learn and easy to teach.
  It is also much harder to abuse Python than C++ or Fortran
    (for instance with \prog{goto} statements, employment of the preprocessor,
    or the implicit typing in Fortran).

  Python implementations do not expose users to compilation or linking processes. 
  As a result, Python-written software is easier to deploy and share, especially 
    if multiple architectures and operating systems are targeted.
  However, there exist tools such as CMake\footnote{CMake is a family of open-source, cross-platform
    tools automating building, testing and packaging of C/C++/Fortran software,
    see \url{http://cmake.org/}}
    that allow to efficiently automate 
    building, testing and packaging of C++ and Fortran programs.

  Python is definitely easiest to debug among the three languages.
  Great debugging tools for C++ do exist, however the debugging and development is 
    often hindered by indecipherable compiler messages
    flooded with lengthy type names stemming from employment of templates.
  Support for the OOP features of Fortran among free and open source compilers, 
    debuggers and other programming aids remains immature.
    
  With both Fortran and Python, the memory footprint caused by employment
    of temporary objects in array arithmetics is dependant on compiler choice or
    the level of optimisations.
  In contrast, Blitz++ ensures temporary-array-free computations by design
    \citep{Veldhuizen_et_al_1997} avoiding unintentional performance loss.

  \subsection{Added values}

  The size of the programmers' community of a given language 
    influences the availability of trained personnel, 
    reusable software components and information resources.
  It also affects the maturity and quality of compilers and tools. 
  Fortran is a domain-specific language while Python and C++ are general-purpose languages
    with disproportionately larger users' communities.
  The OOP features of Fortran have not gained
    wide popularity among users \citep{Worth_2008}\footnote{An anecdotal yet significant
    example being the incomplete support for syntax-highlighting of modern Fortran in Vim and Emacs editors}.
  Fortran is no longer routinely taught at the universities \citep{Kendall_et_al_2008},
    in contrast to C++ and Python.
  An example of decreasing popularity of Fortran in academia 
    is the discontinuation of Fortran printed editions of the ''Numerical Recipes'' 
    series of Press et al.
 
  Blitz++ is one of several packages that offer high-performance object-oriented
    array manipulation functionality with C++ (and is not necessarily optimal for every
    purpose \citep{Iglberger_et_al_2012}).
  In contrast, the NumPy package became a de facto standard solution for Python.
  Consequently, numerous Python libraries adopted NumPy but
    there are apparently very few C++ libraries offering Blitz++ support out of the box
    (the gnuplot-iostream used in listing C.24 being a much-appreciated counterexample).
  However, Blitz++ allows to interface with virtually any library (including Fortran libraries), 
    by resorting to referencing the underlying memory with raw pointers.
 
  The availability and quality of libraries 
    that offer object-oriented interfaces
    differs among the three considered languages.
  The built-in standard libraries of Python and C++ are richer than
    those of Fortran and offer versatile data types, collections of
    algorithms and facilities for interaction with host operating system.
  In the authors' experience, the small popularity of OOP techniques among
    Fortran users is reflected in the library designs (including the Fortran's
    built-in library routines).
  What makes correct use of external libraries more difficult with Fortran
    is the lack of standard exception handling mechanism, a feature
    long and {\em much requested by the numerical community} \citep[][Foreword]{Press_et_al_1996}.

  Finally, the three languages differ as well with regard to availability of 
    mechanisms for leveraging shared-memory parallelisation (e.g. with multi-core processors).
  GCC supports OpenMP with Fortran and C++.
  The CPython and PyPy implementations of Python do not offer any
    built-in solution for multi-threading. 
  
  \conclusions[Summary and outlook]\label{sec:concl}

  Three implementations of a prototype solver 
    for the advection equation were introduced.
  The solvers are based on MPDATA - an algorithm of particular applicability
    in geophysical fluid dynamics \citep{Smolarkiewicz_2006}.
  All implementations follow the same object-oriented structure but are implemented
    in three different languages (or language-library pairs):
  \begin{itemize}
    \item{C++ with Blitz++;}
    \item{Python with NumPy;}
    \item{Fortran.}
  \end{itemize}

  Presented programs were developed making use of such recent
    developments as support for C++11 and Fortran 2008 in GCC, and
    the NumPy support in the PyPy implementation of Python.
  The fact that all considered standards are open and the employed
    tools implementing them are free and open-source
    is certainly an advantage \citep[][sect.~28.2.5]{Anel_2011,Syvitski_et_al_2013}.

  The key conclusion is that all considered language/library/compiler
    set-ups offer possibilities for using OOP to compactly 
    represent the mathematical abstractions within the program code. 
  This creates the potential to improve code readability and brevity,
  \begin{itemize}
    \item{contributing to its 
      auditability, indispensable for credible and reproducible research in computational science 
      \citep{Post_et_al_2005, Merali_et_al_2010, Stodden_et_al_2012}; and
    }
    \item{helping to keep the programs maintainable and avoiding accumulation of the code 
      debt\footnote{See \citet{Buschmann_2011} for discussion of technical/code debt.} 
      that besets scientific software in such domains as climate modelling
      \citep{Freeman_et_al_2010}.
    }
  \end{itemize}
  \noindent 
  The performance evaluation revealed that:
    \begin{itemize}
      \item{the Fortran set-up offered shortest execution times,}
      \item{it took the C++ set-up less than twice longer to compute than Fortran,}
      \item{C++ and PyPy set-ups offered significantly smaller memory consumption 
        than Fortran and CPython for larger domains,}
      \item{the PyPy set-up was roughly twice slower than C++ and up to twice faster than CPython.}
    \end{itemize}
  The three equally-structured implementations required ca. 200, 300, and 500 lines of code 
    in Python, C++ and Fortran, respectively.  

  In addition to the source code presented within the text,
    a set of tests and build-/test-automation scripts
    allowing to reproduce the analysis and plots presented in section~\ref{sec:perf} are all 
    available in the electronic supplement and at
    the project repository\footnote{git repository at \url{http://github.com/slayoo/mpdata/}},
    and are released under the GNU GPL license \citep{GPLv3}.
  The authors encourage to use the presented codes for teaching and benchmarking purposes.

  The OOP design enhances the possibilities to reuse and extend the presented code.
  Development is underway of an object-oriented C++ library featuring concepts presented herein,
    supporting integration in one to three dimensions, handling systems of equations with source terms, 
    providing miscellaneous options of MPDATA and several parallel processing approaches.

%%%%%% <arXiv>
%  \clearpage
%%%%%% </arXiv>
  \appendix

  %\setcounter{section}{15} 
  \section{Python code for sections \ref{sec:cyclic}--\ref{sec:mpdatasolver}}\label{app:P}

  \subsection*{{\bf Periodic Boundaries} (cf. Sect. \ref{sec:cyclic})}
  \noindent 
  \codepyt{code-pyt-listings.py}{listing08}{listing09}{1}

  \subsection*{{\bf Donor-cell formul\ae}~(cf. Sect. \ref{sec:donor})}
  \codepyt{code-pyt-listings.py}{listing09}{listing10}{1}
  \codepyt{code-pyt-listings.py}{listing10}{listing11}{1}
  \codepyt{code-pyt-listings.py}{listing11}{listing12}{1}

  \subsection*{{\bf Donor-cell solver} (cf. Sect. \ref{sec:donorcell_solver})}
  \codepyt{code-pyt-listings.py}{listing12}{listing13}{1}

  \subsection*{{\bf MPDATA formul\ae}~(cf. Sect. \ref{sec:mpdata})}
  \codepyt{code-pyt-listings.py}{listing13}{listing14}{1}
  \codepyt{code-pyt-listings.py}{listing14}{listing15}{1}
  \codepyt{code-pyt-listings.py}{listing15}{listing16}{1}
  \codepyt{code-pyt-listings.py}{listing16}{listing17}{1}
  \codepyt{code-pyt-listings.py}{listing17}{listing18}{1}

  \subsection*{{\bf An MPDATA solver} (cf. Sect. \ref{sec:mpdatasolver})}
  \codepyt{code-pyt-listings.py}{listing18}{listing19}{1}

  \subsection*{{\bf Usage example} (cf. Sect. \ref{sec:example})}
  \codepyt{code-pyt-test.py}{listing19}{listing20}{1}

  %\setcounter{section}{5} 
  \section{Fortran code for sections \ref{sec:cyclic}--\ref{sec:mpdatasolver}}\label{app:F}

  \subsection*{{\bf Periodic boundaries} (cf. Sect. \ref{sec:cyclic})}
  \codefor{code-for-listings.f}{listing08}{listing09}{1}

  \subsection*{{\bf Donor-cell formul\ae}~(cf. Sect. \ref{sec:donor})}
  \codefor{code-for-listings.f}{listing09}{listing10}{1}
  \codefor{code-for-listings.f}{listing10}{listing11}{1}
  \codefor{code-for-listings.f}{listing11}{listing12}{1}
  \codefor{code-for-listings.f}{listing12}{listing13}{1}
  \codefor{code-for-listings.f}{listing13}{listing14}{1}

  \subsection*{{\bf Donor-cell solver} (cf. Sect. \ref{sec:donorcell_solver})}
  \codefor{code-for-listings.f}{listing14}{listing15}{1}

  \subsection*{{\bf MPDATA formul\ae}~(cf. Sect. \ref{sec:mpdata})}
  \codefor{code-for-listings.f}{listing15}{listing16}{1}
  \codefor{code-for-listings.f}{listing16}{listing17}{1}
  \codefor{code-for-listings.f}{listing17}{listing18}{1}
  \codefor{code-for-listings.f}{listing18}{listing19}{1}
  \codefor{code-for-listings.f}{listing19}{listing20}{1}
  \codefor{code-for-listings.f}{listing20}{listing21}{1}
  \codefor{code-for-listings.f}{listing21}{listing22}{1}

  \subsection*{{\bf An MPDATA solver} (cf. Sect. \ref{sec:mpdatasolver})}
  \codefor{code-for-listings.f}{listing22}{listing23}{1}

  \subsection*{{\bf Usage example} (cf. Sect. \ref{sec:example})}
  \codefor{code-for-test.f}{listing23}{listing24}{1}
  \codefor{code-for-test.f}{listing25}{listing26}{1}

  \begin{acknowledgements}
    We thank Piotr Smolarkiewicz and Hanna Paw≈Çowska for their help throughout the project.
    This study was partly inspired by the lectures of Lech ≈Åobocki.

    Tobias Burnus, Julian Cummings, Ond\v{r}ej \v{C}ert\'ik, Patrik Jonsson,
      Arjen Markus, Zbigniew Piotrowski, Davide Del Vento and Janus Weil 
      provided valuable feedback to the initial version of the
      manuscript and/or responses to questions posted to Blitz++ and gfortran mailing lists.
    
    SA, AJ and DJ acknowledge funding from the Polish National Science Centre
      (project no. 2011/01/N/ST10/01483).

    Part of the work was carried out during a visit of SA to the National
      Center for Atmospheric Research (NCAR) in Boulder, Colorado, USA.
    NCAR is operated by the University Corporation for Atmospheric Research.
    The visit was funded by the Foundation for Polish Science (START programme).
 
    Development of NumPy support in PyPy was led by Alex Gaynor, Matti Picus and MF.
  \end{acknowledgements}

  \bibliographystyle{copernicus}
  \bibliography{paper}
  
\end{document}
